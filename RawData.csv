,summary
0,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<p><strong>We are working on building the next $100M revenue Fintech company (founded in Europe)<br/>
<br/>
</strong></p><br/>
<p> <br/>
<br/>
<br/>
</p> <p>To do this, we know we need the <strong>best product in the world</strong> and that means we are obsessed by bringing together the most talented team possible; with diverse experiences, backgrounds and skills.<br/>
<br/>
</p> <p>We have a variety of backgrounds in our team, from people who joined us with zero experience (through the Code Academy - read more here) to those who have spent lots of time in huge companies with bags of experience.<br/>
<br/>
</p> <p>We are focused on delivering world class software products that deliver true value. With 1000's of enterprise customers like Expedia, Chubb, XPO - we must be doing something right. But the journey is just beginning... <strong>we have 100k users on our platform every month and handle more than $2 trillion of invoice transactions.<br/>
<br/>
</strong></p> <p>At approx. $35M revenue today and with about 250 Sidetraders worldwide, we are not an early-stage start-up, but with ambitious plans for growth, we are at an exciting time in our story; and need the right talent to help us achieve our goals.<br/>
<br/>
</p> <p><strong>Challenges you will face<br/>
<br/>
</strong></p><br/>
<ul> <li>Design and develop robust data pipelines. Data is at the heart of everything we do. The pipelines you build will power our analytics, machine learning and product features</li> <li>Build tools and automation capabilities for data pipelines. The data we ingest and the appetite to consume it is ever increasing - and therefore so is the importance of making data integration more reliable and scalable</li> <li>Extend our Data Warehouse and Data Lake to empower data-driven decisions</li> <li>Help build a data-platform to democratize data - we want to create a single source of truth of all our data, which is open to and consumable by everyone at Sidetrade</li> <li>Support implementation of secure design principles according to policies and standards of Information Security</li> </ul><br/>
<p><strong>How our teams are structured<br/>
<br/>
</strong></p><br/>
<p>We have three Tech Hubs at Sidetrade, one in Birmingham (UK), one in Paris (France) and one in Calgary (Canada). We work in small, autonomous teams mixed with highly skilled engineers, usually up to a maximum of 7. Each team (or Squad) has a Product Manager, Technical Lead, a mix of engineers and dedicated QA.<br/>
<br/>
</p><br/>
<p>Each Squad has the autonomy to decide how they work best, within a basic Agile framework and work on strategic, customer-focused projects that deliver huge value.<br/>
<br/>
</p><br/>
<p><strong>Guilds<br/>
<br/>
</strong></p><br/>
<p>As well as our day-to-day teams who focus on product delivery, we also have what we call Guilds. These Guilds or groups of like-minded engineers, focus on specific technologies to focus/harness passion on deep technical expertise as well as following latest market trends. Anybody can join a guild (UI/UX, API's &amp; Gateway, Data Engineering, Data Science, SRE, Test) - so either it's your passion or you just want to learn something new.<br/>
<br/>
</p><br/>
<p><strong>You should apply if:<br/>
<br/>
</strong></p> <ul> <li>You have at least 3 years' experience in Data Engineering</li> <li>You have excellent knowledge of SQL and Python</li> <li>You have a good understanding of relational and NoSQL databases (including data modelling, data warehousing)</li> <li>You are experienced in developing and supporting robust, automated and reliable data pipelines (maybe using technologies such as Kafka, Airflow, Celery etc.)</li> <li>You are familiar with Agile and DevOps frameworks</li> <li>You have sound knowledge of data architecture, scalability and security/compliance</li> </ul> <p><strong>What we can offer you:<br/>
<br/>
</strong></p><br/>
<ul> <li>The chance to deliver features to huge B2B customers that have 1000's of active users every day like Expedia, Nespresso, XPO, Manpower and many more.</li> <li>The chance to work for a European hyper-growth European AI company with recent acquisition in US.</li> <li>The chance to work in a hybrid-remote environment with the option to work from home and as well as our Boulogne Tech Hub, with regular travel opportunities (if you'd like).</li> <li>The chance to work in a Guild of your choice with dedicated time available to work together on Guild-based tasks, like research, learning, mini hackathons etc.</li> <li>Full access to content on Udemy so that you can self-learn,</li> <li>The opportunity to work remotely from France and onsite</li> <li>The chance to work in an international environment speaking english with your Birmingham collegues on a daily basis</li> <li>25 days holiday + bank holidays + RTT</li> <li>Healthcare plan</li> </ul> <p>If you have previous experience as a Data Engineer and are looking for the next step in your career, we would love to hear from you!<br/>
<br/>
</p>
<!-- --> </span>
</div>"
1,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<strong><u>About Morgan Stanley<br/>
<br/>
</u></strong>Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments, and individuals from more than 1,200 offices in 43 countries.<br/>
<br/>
As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence, and strong team ethic. Morgan Stanley can provide a superior foundation for building a professional career ‚Äì a place for people to learn, to achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.<br/>
<br/>
<strong>Risk and Data Analytics Centre, Paris<br/>
<br/>
</strong>As we see increasing client interest in quantitative strategies, maintaining, and enhancing our leading position in risk analytics and technology is critical to our Institutional Securities Group (ISG) businesses globally. The seamless collaboration between technologists and ISG personnel, including data scientists, financial engineers and quantitative analysts helps to deliver innovative tools and solutions that differentiate us from our competitors.<br/>
<br/>
Morgan Stanley is establishing a new Risk &amp; Data Analytics (‚ÄúR&amp;D‚Äù) Centre in Paris, where it will support our growth strategy for ISG both in EMEA and more broadly. The Centre will deliver cutting-edge, proprietary solutions to address the rapidly changing business needs of our sales and trading franchise while providing a platform to foster innovation for our markets businesses, driven by analytical and technological excellence.<br/>
<br/>
<strong>Technology at Morgan Stanley <br/>
<br/>
</strong>Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award winning technology platforms that help to propel our Firm‚Äôs businesses to be the top in the market. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.<br/>
<br/>
<strong>What will you be doing?<br/>
<br/>
</strong>A Data Analytics and Platform team within the Institutional Securities Technology division is seeking a collaborative, hands-on developer to build best-in-class solutions for Data APIs, Data Governance, Data Quality, Security &amp; Privacy, and Architecture. This role offers a unique opportunity to work in a state-of-the-art modern data stack using open-source technologies aligned with our cloud strategy. We are looking for a proficient developer who is excited about innovation, with a proven track record of delivery.<br/>
<br/>
<strong><u>Roles And Responsibilities Include<br/>
</u></strong><ul><li>You will work closely with quants and traders on multiple trading desks to design, develop, deploy and support the innovative data science environment </li><li>Design widely used and flexible APIs to our core data and functionality </li><li>Analyze and optimize performance of large data workloads using compute clusters </li><li>Stay up to date with emerging trends and tools in the data &amp; analytics domain </li><li>Provide support and design advice to users of the cross-asset platform </li><li>Work closely with strategists and other stakeholders to help move their financial assets, valuation models and data pipelines to the platform </li><li>Efficient Communication across regions and functions <br/>
</li></ul><strong><u>What We‚Äôre Looking For<br/>
<br/>
</u></strong>We have a number of roles available for a range of technologists at different experience levels to join the team who will need;<br/>
<ul><li>Excellent problem solving and code development skills </li><li>Ability and interest to research, learn and implement new Data and Analytics technologies and paradigms </li><li>Enterprise level software development practices </li><li>Strong oral and written communication skills </li><li>Strong team working ability in local and global teams </li><li>Passion for continuous improvement both personally and as a team <br/>
</li></ul><strong><u>Skills That Will Help You In The Role<br/>
</u></strong><ul><li>Experience with at least one of the following technologies: Python and/or Java </li><li>Experience with performance optimization and concurrent programming </li><li>Exposure to Flask/Numpy/pandas/Plotly/Jupyter/Airflow and general data science stack experience </li><li>Exposure to Natural Language Processing, Machine Learning and other advanced methods of Data Management </li><li>Exposure to grid distributed applications </li><li>Exposure to KDB or other timeseries database technologies </li><li>Exposure to Cloud technologies </li><li>Exposure to Full Stack Web Development </li><li>Exposure to Risk Management systems and a wide range of Financial Instruments <br/>
</li></ul><strong>Where will you be working?<br/>
<br/>
</strong>61, rue de Monceau, 75008 Paris<br/>
<br/>
We integrate global expertise with regional knowledge of France to offer clients outstanding services in investment banking, sales and trading, real estate and distribution of investment management products<br/>
<br/>
<strong><u>Flexible Work Statement<br/>
<br/>
</u></strong>Interested in flexible working opportunities? Morgan Stanley empowers employees to have greater freedom of choice through flexible working arrangements. Speak to our recruitment team to find out more.<br/>
<br/>
<strong><u>Equal Opportunities Statement<br/>
<br/>
</u></strong>Morgan Stanley is an equal opportunities employer. We work to provide a supportive and inclusive environment where all individuals can maximize their full potential. Our skilled and creative workforce is comprised of individuals drawn from a broad cross section of the global communities in which we operate and who reflect a variety of backgrounds, talents, perspectives, and experiences. Our strong commitment to a culture of inclusion is evident through our constant focus on recruiting, developing, and advancing individuals based on their skills and talents.<br/>
<br/>
<strong>Posting Date<br/>
<br/>
</strong>Aug 8, 2022<br/>
<br/>
<strong>Primary Location<br/>
<br/>
</strong>Europe, Middle East, Africa-France-France-Paris<br/>
<br/>
<strong>Education Level<br/>
<br/>
</strong>Bachelor's Degree<br/>
<br/>
<strong>Job<br/>
<br/>
</strong>Engineering<br/>
<br/>
<strong>Employment Type<br/>
<br/>
</strong>Full Time<br/>
<br/>
<strong>Job Level<br/>
<br/>
</strong>Vice President
<!-- --> </span>
</div>"
2,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<p><strong>For details about the offer, see </strong>https://greenly.welcomekit.co/jobs/climate-data-engineer_paris</p>
<!-- --> </span>
</div>"
3,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<p><strong>Who We Are</strong></p><p>Boston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.</p><p>BCG GAMMA combines innovative skills in computer science, artificial intelligence (AI), statistics, and machine learning with deep industry and functional expertise. The BCG GAMMA team is comprised of world-class data scientists, software and data engineers, as well as product experts with a consulting mindset.</p><p>We specialize in creating competitive advantage for our clients through AI driven transformations. Our teams own the full analytics value-chain end to end: framing new business challenges, designing innovative algorithms, implementing and deploying scalable solutions, and enabling colleagues and clients to fully embrace AI. Our product offerings span from fully custom-build to industry specific leading edge AI software solutions.</p><p><br/>
</p><p><strong>What You'll Do</strong></p><p>As a forward-deployed Data Engineer, you‚Äôll be part of our rapidly growing engineering team and help build the next generation of AI solutions. You‚Äôll have the chance to partner with clients in a variety of BCG regions and industries, and on key topics like climate change, enabling them to design, build, and deploy new and innovative solutions. Additional responsibilities will include developing and delivering thought leadership in scientific communities and papers as well as leading conferences on behalf of BCG GAMMA.</p><p><br/>
</p><p><strong>Who You Are</strong></p><p>We are looking for talented individuals with a passion for data engineering, software development and transforming organizations into AI led innovative companies</p><p>¬∑ Apply data engineering practices and standards to develop robust and maintainable solutions</p><p>¬∑ Actively involved in every part of the software development life cycle</p><p>¬∑ Experienced at guiding non-technical teams and consultants in best practices for large-scale data engineering</p><p>¬∑ Motivated by a fast-paced, service-oriented environment and interacting directly with clients on new features for future product releases</p><p>¬∑ Enjoy collaborating in teams to share software design and solution ideas</p><p>¬∑ A natural problem-solver and intellectually curious across a breadth of industries and topics</p><p>What You'll Bring (Experience &amp; Qualifications)</p><p>¬∑ Master‚Äôs Degree in Computer Science or relevant field</p><p>¬∑ Experience in data engineering and working with global and remote agile squads</p><p>¬∑ Proficiency with analytic software programming ideally in python, C++, or SCALA</p><p>¬∑ Fluency with the storage, manipulation, and management of relational, non-relational and streaming data structures, specifically SQL, Spark, and Hadoop</p><p>¬∑ Proficiency with infrastructure as code principles</p><p>¬∑ Experience working on AWS, Azure, or Google cloud infrastructure</p><p><br/>
</p><p><strong>NICE TO HAVE</strong></p><p>¬∑ DevOps: Docker, Kubernetes, CI/CD, Terraform</p><p>¬∑ Understanding of parallel computing</p><p>¬∑ Full stack development: GraphQL, React, JavaScript, TypeScript</p><p>¬∑ Data Science and machine learning (Pandas, Scikit learn)</p><p><br/>
</p><p><strong>WORK ENVIRONMENT</strong></p><p>¬∑ Fluency in English is required as well as fluency in the local language for most locations</p><p>¬∑ Position is located in either Paris, London, Amsterdam, Germany, Nordics, Warsaw, Moscow, Milan, Zurich or Madrid</p><p>¬∑ Ability to travel based on client and business needs. Expect 30-50%</p>
<!-- --> </span>
</div>"
4,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
                Position<p><br/>
</p>Votre r√¥le en tant que Stagiaire Data Engineer sera de participer √† la construction du nouvel environnement data de 24s.com : mise en place d‚ÄôETL (extraction et transformation des donn√©es), data lake, data warehouse, alerting, reportings.<p><br/>
</p><strong><u>Missions</u></strong><p><br/>
</p><ul><li>Participer aux d√©veloppements des flux ETL de la plateforme Data :</li><li>Collecter la donn√©e (source interne, externe) et la stocker sur le data lake Cloud Storage</li><li>Transformer et enrichir la donn√©e dans notre data warehouse BigQuery</li><li>Mettre en place le monitoring adapt√© et assurer l‚Äôint√©grit√© du flux</li><li>Participer √† la documentation de la stack Data</li><li>Mettre en place des contr√¥les / alertes sur la coh√©rence et la qualit√© des donn√©es</li><li>R√©aliser les dashboards sur la base des besoins d√©finis par les √©quipes m√©tiers</li></ul><p><br/>
</p>Vous pouvez √™tre amen√© √† intervenir sur d‚Äôautres missions :<p><br/>
</p><ul><li>Faire √©voluer le tracking web/app n√©cessaire aux analyses / dashboards et recetter son bon fonctionnement</li><li>R√©aliser des analyses de fa√ßon ad-hoc</li></ul><p><br/>
</p>Pourquoi postuler ? :<p><br/>
</p>Rejoindre 24S en tant que Stagiaire Data c‚Äôest saisir l‚Äôopportunit√© de travailler sur des technologies r√©centes (Google Cloud Platform, AWS) dans une entreprise en pleine croissance.<p><br/>
</p>Profile<p><br/>
</p><ul><li>Vous √™tes en derni√®re ann√©e d‚Äô√©cole d‚Äôing√©nieur ou √©quivalent universitaire</li><li>Vous avez d‚Äôexcellentes comp√©tences en Python et SQL</li><li>Vous √™tes curieux, dynamique et rigoureux</li><li>Id√©alement, vous connaissez d√©j√† l‚Äôenvironnement Google Cloud Platform et du d√©veloppement javascript</li></ul><p><br/>
</p>La maison 24S reconnait et recrute tous les talents.<p><br/>
</p><ul><li>Contract type: Stage</li></ul>
<!-- --> </span>
</div>"
5,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<strong>Concr√®tement votre quotidien ? </strong><p><br/>
</p>Ce poste consistera √† mettre √† disposition de STFS les donn√©es n√©cessaires aux stress tests cr√©dit.<p><br/>
</p>En tant que Data Engineer, vous comprendrez les besoins n√©cessaires pour l'ex√©cution des diff√©rents exercices de stress tests. Vous participerez √† la formulation de la demande/sp√©cification du besoin, collecterez la donn√©e, la traiterez, l'analyserez et la structurerez.<p><br/>
</p>Cela demandera une connaissance fonctionnelle du cr√©dit et des besoins sp√©cifiques li√©s √† l'activit√© de l'√©quipe de mod√©lisation de STFS (STMM).<p><br/>
</p>Les base de donn√©es, r√©sultats de ce travail, seront fournies √† STMM et au moteur de stress test afin de pouvoir effectuer des projections d'actifs pond√©r√©s et de co√ªt du risque, d√©pendantes de sc√©narios macro√©conomiques.<p><br/>
</p>Ces travaux vous demanderont un bon niveau de communication et une tr√®s bonne capacit√© de travail en √©quipe, au sein de STFS d'une part et avec les m√©tiers (march√©s domestiques, CIB, PF, IRB) et fonctions du groupe (RISK et FINANCE) d'autre part.<p><br/>
</p>La donn√©e est c≈ìur du besoin des stress tests cr√©dit. Dans un environnement r√©glementaire toujours plus exigeant, notre capacit√© √† la pr√©parer, la restituer dans des temps courts, avec une qualit√© optimale, sont cl√©s.<p><br/>
</p><strong>L'environnement de travail, c'est important ! </strong><p><br/>
</p>BNP PARIBAS Group Finance, RISK and ALM Treasury ont mis en place une √©quipe en JV en charge des stress test Groupe, financial planning et la synth√®se financi√®re appel√©e STFS pour Stress Testing and Financial Synthesis.<p><br/>
</p>Au sein de la plateforme STFS, Stress Testing and Data Analytics (STDA), est responsable de la mise √† disposition des donn√©es n√©cessaires √† l'ex√©cution des exercices de stress tests internes et r√©glementaires sur l'ensemble des risques mat√©riels du groupe (cr√©dit, titrisation, risque de march√© du banking book...). STDA est aussi responsable de certains reportings r√©glementaires dans lesquels STFS est impliqu√©.<p><br/>
</p>L'√©quipe est compos√©e d'experts fonctionnels afin de comprendre et formaliser le besoin de donn√©es, mais aussi techniques afin de structurer, contr√¥ler, d√©velopper des solutions de mise √† disposition de ces donn√©es. Sur le cr√©dit, les bases de donn√©es moteur sont mises √† disposition du moteur de stress test groupe pour fournir des projections d'actifs pond√©r√©s et de co√ªt du risque. STDA est un des principaux utilisateurs de la plateforme de stress testing du groupe (PROMETHEE).<p><br/>
</p>Le poste est bas√© au Mill√©naire 1, Paris 19√®me. Vous pourrez t√©l√©travaillez jusqu'√† 2,5 jours par semaine.<p><br/>
</p><strong>Et apr√®s ? </strong><p><br/>
</p>Cette position transverse offre de nombreuses opportunit√©s de travailler avec des acteurs dans de nombreuses r√©gions et d'appr√©hender et comprendre les diff√©rents m√©tiers dans le Groupe.<p><br/>
</p><strong>Et la r√©mun√©ration ?</strong><p><br/>
</p>Nous saurons valoriser votre talent. Discutons-en !<p><br/>
</p><strong>Pourquoi BNP Paribas ? </strong><p><br/>
</p>Notre monde change : notre mani√®re de nous informer, de consommer‚Ä¶ et de travailler aussi ! Aujourd‚Äôhui, ce qui compte dans un job, c‚Äôest de vivre de v√©ritables exp√©riences, d‚Äôapprendre, de partager objectifs et r√©sultats avec ses coll√®gues.<p><br/>
</p>Bref, de tracer son propre chemin, diff√©rent, responsable et durable.<p><br/>
</p>Chez BNP Paribas, nous recrutons nos collaborateurs avec l‚Äôid√©e qu‚Äôils nous aideront √† concevoir le monde et la banque de demain.<p><br/>
</p>Vous voulez conna√Ætre toutes les raisons de nous rejoindre ? Rendez-vous sur www.bnpparibas.com<p><br/>
</p><strong>Et vous ? </strong><p><br/>
</p>Vous √™tes dipl√¥m√© d‚Äôun Bac+5 et vous avez une exp√©rience de 5 ans minimum en tant que Data analyst en risque/finance. Vous ma√Ætrisez SQL et Python.<p><br/>
</p>Votre niveau d‚Äôanglais est avanc√© aussi bien √† l‚Äôoral qu‚Äô√† l‚Äô√©crit.<p><br/>
</p>Vous avez d√©velopp√© de bonnes capacit√©s √† collaborer et √† communiquer.<p><br/>
</p>Votre rigueur, votre capacit√© d‚Äôanalyse alli√©es √† votre capacit√© d‚Äôorganisation seront des atouts pour r√©ussir sur ce poste.<p><br/>
</p>Dans un monde qui change, la diversit√©, l‚Äô√©quit√© et l‚Äôinclusion sont des valeurs cl√©s pour le bien-√™tre et la performance des √©quipes.<p><br/>
</p>Chez BNP Paribas, nous souhaitons accueillir et retenir tous les talents sans distinction : c‚Äôest ainsi que nous construirons, ensemble, la finance de demain, innovante, responsable et durable.<p><br/>
</p>Enfin, nous attachons une importance particuli√®re √† ce que nos futurs collaborateurs agissent au quotidien avec responsabilit√© √©thique et professionnelle.<p><br/>
</p>√Ä tout moment pendant le processus de recrutement, les informations figurant sur votre CV, vos donn√©es d'identification et vos ant√©c√©dents pourront √™tre v√©rifi√©s.<p><br/>
</p><strong>Lieu principal</strong><p><br/>
</p>FR-√éle-de-France-PARIS<p><br/>
</p><strong>Type d'emploi</strong><p><br/>
</p>CDI<p><br/>
</p><strong>Domaine d'activit√©</strong><p><br/>
</p>EFFICACIT√â OP√âRATIONNELLE TRANSFORMATION ET MOA (OU BA)<p><br/>
</p><strong>Niveau d%27Etudes</strong><p><br/>
</p>Master ou √©quivalent (&gt; 4 ans)<p><br/>
</p><strong>Niveau d%27exp√©rience</strong><p><br/>
</p>Au moins 5 ans<p><br/>
</p><strong>Horaire</strong><p><br/>
</p>Temps plein<p><br/>
</p><strong>Langue (1)</strong><p><br/>
</p>Anglais
<!-- --> </span>
</div>"
6,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<p>Dailymotion is seekinga Data(Analytics)Engineer for the Analytics Engineering team.<br/>
<br/>
</p><p>You will join the Data Engineering &amp; Machine Learning craft. A craft consists of multiple teams of engineers and machine learning experts who collaborate daily to create and run Data products in Dailymotion. Inside this craft, the Analytics Engineering team‚Äôs mission is to provide trustworthy and available data to enable analysis &amp; insights throughout the company (B2C, B2B products, and business teams).<br/>
<br/>
</p><p>Analytics Engineering team builds and maintains products likeourmulti-petabyte data warehouse, event processors (at tens of thousands of messages per second), highly scalable client-facing analytics, data ingestion &amp; distribution, synchronizing data across databases &amp; systems, etc. The team is responsible for making costs-performance tradeoffs around data modeling &amp; architecture. The team is also involved with training users of our data on SQL and analytics best practices and spearheading a significant effort around data governance.<br/>
<br/>
</p><p>Analytics Engineering is a new and emerging space within the Data sphere. As an Analytics Engineer, you bring a software engineering mindset, best practices to maintain analytics code, and to model data from its source to its use in the data warehouse as business and reporting data. It requires a mix of programming skills and data skills on a day-to-day basis. If you are interested in solving challenging business problems with your skills, consider applying to this role. Your impact will be broad and across all of Dailymotion‚Äôs businesses.<br/>
<br/>
</p><p><strong>Whatyou will do:<br/>
<br/>
</strong></p><ul><li><p>Collect vast amounts of raw data from internal sources and external sources in batch and streaming modes.<br/>
<br/>
</p></li></ul><ul><li><p>Expose the data through APIs, flat files, data marts, etc., for internal and external users.<br/>
<br/>
</p></li><li><p>Design Druid datasets for external facing consumers for speed, consistency, cost, and efficiency.<br/>
<br/>
</p></li><li><p>Write complex and optimal SQL queries to transform data in our data lake into reliable business entities and then into reporting aggregates. Identify dependencies for these transformations. Schedule these transformations through Airflow.<br/>
<br/>
</p></li><li><p>Investigate data discrepancy, data quality issues. Debug performance issues using query plan.<br/>
<br/>
</p></li><li><p>DesignBigQuerytable data model to efficiently answer business use cases considering cost and performance.<br/>
<br/>
</p></li></ul><ul><li><p>Ensure data is clean, consistent, and available. Perform data quality checks, create monitors.<br/>
<br/>
</p></li><li><p>Catalogand documentthe business entities, data marts, dimensions, metrics, business rules, etc.<br/>
<br/>
</p></li><li><p>Be a knowledge guide on the various business entities, data marts. Train users of our data on SQL and analytics best practices.<br/>
<br/>
</p></li><li><p>Come up with new tools, processes, documents and explore new tech during the cool-down periods.<br/>
<br/>
<br/>
<br/>
</p></li></ul><strong>Qualifications<br/>
<br/>
</strong><ul><li>BS/MS in Computer Science, Engineering or related field</li><li><p>2+ years experiencearound Big Data, Data warehousing, writing complex SQL, and debugging complex SQL.<br/>
<br/>
</p></li><li><p>1+ years of experience developing and debugging software inPython.<br/>
<br/>
</p></li></ul><ul><li><p>Good business modeling skills: going from a stakeholder‚Äôs expressed requirements to an actual data model.<br/>
<br/>
</p></li><li><p>Ability to work with multiple stakeholders-Product, Engineers, Analysts,Product managers, DevOps, etc.<br/>
<br/>
</p></li><li><p>Comfortable working with Linux and the GCP stack<br/>
<br/>
</p></li><li><p>Experience withPubSub, Data flow, Data Processor, Airflow or Kafka, Spark, or other streaming technologies is a plus.<br/>
<br/>
</p></li><li><p>Experience in real-time analytics databases like Apache Druid is a plus.<br/>
<br/>
</p></li></ul><ul><li><p>Familiarity with NoSQL technologies such as Aerospike is a plus.<br/>
<br/>
</p></li><li><p>Writing and speaking proficiency in English<br/>
<br/>
</p></li></ul><p><strong>Technologies used by the team:<br/>
</strong>Google Cloud Platform (BigQuery, Cloud Storage, Beam/Dataflow, Compute Engine,etc), Python, GO, Airflow, SQL, Git, Java, JSON, Bash, Docker, Druid, Kubernetes, etc<br/>
<br/>
<br/>
<br/>
</p><strong>Additional Information<br/>
<br/>
</strong><p>At Dailymotion, we empower candidates to take action. If this job sounds like a great opportunity for you, be confident in your skills, we are always happy to meet you! If needed, we can accommodate our recruitment process for your special abilities.<br/>
<br/>
</p><p>Location:Remote in France / Sophia Antipolis / Paris<br/>
Type of contract: Permanent<br/>
Start Date: ASAP<br/>
<br/>
</p><p><u>For the France offices üá´üá∑<br/>
<br/>
</u></p><p>üè°Hybrid Work Framework (4 types of remote work:Full office /Flex office (1/2 days remote) / Flex remote (1/2 days at the office) / Full remote + ability to work 3 months abroad)<br/>
üí∞International Group Savings Plan offered through the Vivendi Group<br/>
üçº8weeks paid Paternity leave or Co-parental leave<br/>
üï∂Ô∏èExcellent Employee Culture (Company Events / Training / Parties / All hands ‚Ä¶)<br/>
üöÄCareer development support (training / career check-in with HR / internal mobility / compensation cycle / 360 quarter feedback review ‚Ä¶)<br/>
üè•Company-paid Health Insurance andPersonal Services Vouchers (CESU)<br/>
üöÜCommuter benefit coverage - Public Transport and Bike refund<br/>
‚õ±Ô∏èPaid Time off ‚Äì RTT and Saving time plan (CET)<br/>
‚úÖMeal Vouchers<br/>
üé°Workers representatives committee(sports membership/cinemas vouchers/gift vouchers/discount)<br/>
<br/>
</p><p><br/>
<u>Feel free to explore Dailymotionculture a little further, please check out:<br/>
<br/>
</u></p><ul><li>Dailymotion.com</li><li>New-York office - BuiltIn</li><li>Offices in France - Welcome to the Jungle</li><li>Our articles</li></ul>
<!-- --> </span>
</div>"
7,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<strong><u>About Us</u></strong><p><br/>
</p><strong>Description</strong><p><br/>
</p><i>Kaspr is a SaaS business, helping salespeople, recruiters and marketers in their lead generation efforts. Kaspr is the leader of the French SMB market and is making major strides towards becoming the European leader in the space.</i><p><br/>
</p><i>The concept is simple - retrieve contact information from identified LinkedIn profiles, via a Google Chrome extension.</i><p><br/>
</p><i>There‚Äôs never been a more exciting time to join the Kaspr team ‚Äì having recently been acquired by Cognism, Kaspr is expanding globally and rapidly having launched into 10 new countries in the past three months alone. Our people, culture (and vibrant new offices!) ensure all our employees feel empowered to succeed in their roles, while having fun along the way. We‚Äôd love to hear from you!</i><p><br/>
</p><strong><u>Summary</u></strong><p><br/>
</p>We are now looking for an mid-level Data Engineer to join our fast-growing team. You will be responsible for building new systems that collect, manage, and convert raw data into usable information to analyze.<p><br/>
</p>The ideal candidate is an experienced with big data pipelines and a natural data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our team and will ensure optimal data delivery architecture is consistent throughout on going projects.<p><br/>
</p>If you are detail-oriented, with excellent organizational skills and experience in this field, we‚Äôd like to hear from you.<p><br/>
</p><strong><u>Key Responsibilities</u></strong><p><br/>
</p>Building new systems that collect, manage, and convert raw data into usable information.<p><br/>
</p>Support our team on data initiatives<p><br/>
</p>Participate in all phases of software development including concept, design, prototyping, and production release<p><br/>
</p>Work directly with non-technical associates to understand business requirements<p><br/>
</p><strong><u>Requirements</u></strong><p><br/>
</p><strong>Our ideal candidate will:</strong><p><br/>
</p><ul><li> Have a 2+ years of experience as a software engineer</li><li> Have a degree in Computer Science, Computer Engineering, Applied Statistics, Mathematics, or a related field (or you are in the process of achieving one).</li><li> Have some programming experience with JavaScript/Python and NoSQL and are familiar with the principles of software engineering and data analytics.</li><li> Be excited to try new technologies and develop your technical skills.</li><li> Have know-how of designing and interacting with databases (SQL/NoSql).</li><li> Have experience with AWS-based database systems.</li><li> Be familiar with GIT and release engineering strategies.</li><li> Be proficient in spoken and written English.</li></ul><p><br/>
</p><strong><u>Benefits</u></strong><p><br/>
</p><ul><li>Insurance ‚ÄúMutuelle‚Äù : 50% is covered by the company</li><li>Transport tickets : 50% is covered by the company</li><li>Swile card : 10‚Ç¨ per lunch ticket 50% is covered by the company</li><li>Coffee/tea/beer free</li><li>Remote work 2 days/month</li><li>Breakfast every Mondays</li><li>Lunch free once per month</li><li>Days off : Each employee earns 2.5 days off per month ( pro rate if missing working days ) total of 30 days per year. Friday counts as 2 days</li></ul>
<!-- --> </span>
</div>"
8,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<p>Votre r√¥le en tant que Stagiaire Data Engineer sera de participer √† la construction du nouvel environnement data de 24s.com : mise en place d‚ÄôETL (extraction et transformation des donn√©es), data lake, data warehouse, alerting, reportings.</p><p><br/>
</p><p><u>Missions :</u></p><ul><li>Participer aux d√©veloppements des flux ETL de la plateforme Data :</li><li>Collecter la donn√©e (source interne, externe) et la stocker sur le data lake Cloud Storage</li><li>Transformer et enrichir la donn√©e dans notre data warehouse BigQuery</li><li>Mettre en place le monitoring adapt√© et assurer l‚Äôint√©grit√© du flux</li><li>Participer √† la documentation de la stack Data</li><li>Mettre en place des contr√¥les / alertes sur la coh√©rence et la qualit√© des donn√©es</li><li>R√©aliser les dashboards sur la base des besoins d√©finis par les √©quipes m√©tiers</li></ul><p>Vous pouvez √™tre amen√© √† intervenir sur d‚Äôautres missions :</p><ul><li>Faire √©voluer le tracking web/app n√©cessaire aux analyses / dashboards et recetter son bon fonctionnement</li><li>R√©aliser des analyses de fa√ßon ad-hoc</li></ul><p><br/>
</p><p>Pourquoi postuler ? :</p><p>Rejoindre 24S en tant que Stagiaire Data c‚Äôest saisir l‚Äôopportunit√© de travailler sur des technologies r√©centes (Google Cloud Platform, AWS) dans une entreprise en pleine croissance. </p><p><br/>
</p><p><u>Profil recherch√© :</u></p><ul><li>Vous √™tes en derni√®re ann√©e d‚Äô√©cole d‚Äôing√©nieur ou √©quivalent universitaire</li><li>Vous avez d‚Äôexcellentes comp√©tences en Python et SQL</li><li>Vous √™tes curieux, dynamique et rigoureux</li><li>Id√©alement, vous connaissez d√©j√† l‚Äôenvironnement Google Cloud Platform et du d√©veloppement javascript</li></ul><p><br/>
</p><p>La maison 24S reconnait et recrute tous les talents.</p>
<!-- --> </span>
</div>"
9,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<p>Equancy est un cabinet de conseil international, bas√© √† Paris et Duba√Ø, sp√©cialis√© dans la transformation data des entreprises.</p><p><br/>
</p><p>Nous planifions, concevons et mettons en ≈ìuvre des solutions Big Data, Data Science et Intelligence Artificielle pour nos clients. Nos projets vont de la mise en ≈ìuvre d‚Äôinfrastructures sp√©cialis√©es dans le traitement de la donn√©e de nos clients, de lacs de donn√©es jusqu‚Äôau d√©veloppement de syst√®mes op√©rationnels int√©grant des algorithmes de <i>machine learning</i> ou de <i>deep learning</i>. Nous sommes experts dans l‚Äôindustrialisation de ces plates-formes, en appliquant les principes du devops √† nos infrastructures data.</p><p><br/>
</p><p>Nos clients sont de grands groupes fran√ßais et internationaux (LVMH, Picard, Chanel VINCI, Volkswagen). Ils nous font confiance autant dans l‚Äôaccompagnement au cadrage de leurs besoins que dans la r√©alisation des solutions data innovantes.</p><p><br/>
</p><p>En tant que <strong>Data Engineer</strong>, rattach√© au p√¥le Data Technologies d'Equancy, vous serez amen√©(e) √† intervenir sur des missions vari√©es :</p><p><br/>
</p><ul><li>Accompagnement projet dans les diff√©rentes √©tapes de build de plateformes (datalake, dashboards, ‚Ä¶);</li><li>Conception de pipeline d'ingestion et traitement de donn√©es (cycle de vie de la donn√©e);</li><li>D√©veloppement de briques ETL, transformation de flux batch et temps r√©el;</li><li>Cr√©ation de mod√®le de donn√©es;</li><li>Pr√©paration √† la mise en production de cas d'usage et industrialisation (accompagnement des data scientists, contribution √† l'am√©lioration d'efficacit√© sur les d√©ploiements);</li><li>Formation, √©vang√©lisation sur des technologies innovantes en interne et aupr√®s de clients;</li><li>Contribution √† la documentation des travaux;</li><li>Participation aux dossiers d‚Äôavant-ventes, √† la r√©daction des r√©ponses et aux soutenances orales.</li></ul><p><br/>
</p><p>Vous assurerez √©galement une veille technologique, et proposerez des solutions standardis√©es, fiables, √©volutives et r√©plicables.</p><p><br/>
</p><p><strong>Profil recherch√©</strong></p><ul><li>De formation BAC+5 ing√©nieur ou universit√©</li><li>Minimum 2 ans d‚Äôexp√©rience sur des sujets Big Data, avec des r√©alisations de projets Datalake et BI/reporting;</li><li>Ma√Ætrise √† minima d'un des environnements Cloud AWS, GCP et Azure;</li><li>De bonnes comp√©tences sur les sujets ou technologies suivantes:</li><li>Framework Spark (pySpark, Scala),</li><li>Pandas et optionnellement scikit-learn ;</li><li>Utilisation de Airflow ;</li><li>ETL ;</li><li>Api REST ;</li><li>Bases de donn√©es SGBDR / NoSQL ;</li><li>Docker ;</li><li>Scripting Python et Shell ;</li><li>Outils d‚Äôint√©gration continue tels que Terraform, Ansible et Jenkins ;</li><li>Outils de d√©veloppement : jupyter Notebook, Pycharm, Git ;</li><li>Une exp√©rience dans le d√©veloppement en contexte agile serait un plus, ainsi que dans la gouvernance de donn√©e (RGPD) et la g√©n√©ration de data catalogue.</li></ul><p><br/>
</p><p>A propos d'Equancy, Equancy c‚Äôest :</p><ul><li>90 consultants</li><li>30 ans d‚Äô√¢ge moyen</li><li>18 ann√©es d‚Äôexistence</li><li>3 bureaux : Paris, Duba√Ø &amp; Mumbai</li><li>3 practices : Strat√©gie, Data Science &amp; Technologie, Marketing Performance</li><li>5 expertises sectorielles : Auto &amp; mobilit√©, Retail &amp; e-commerce, Services financiers, Tourisme &amp; entertainment, Consumer goods</li></ul><p><br/>
</p><p><br/>
</p><p><strong>Conditions de travail/cadre de travail</strong> :</p><ul><li>Poste √† pourvoir d√®s que possible, CDI, statut Cadre;</li><li>R√©mun√©ration attractive;</li><li>Cadre de travail :</li></ul><p>¬∑ Superbes locaux au c≈ìur de Paris : Espace WeWork Jules Lefebvre, √† cot√© de Saint Lazare, au sein d‚Äôun b√¢timent historique, avec de grands espaces et vue panoramique sur tout Paris;</p><p>¬∑ Equilibre vie pro / vie perso;</p><p>¬∑ Une politique de t√©l√©travail de deux jours par semaine;</p><p>¬∑ √âquipement pour travailler en remote + participation aux frais du t√©l√©travail (allocation mensuelle);</p><p>¬∑ Engagement environnemental;</p><p>¬∑ Des activit√©s sportives propos√©es par WeWork x Equancy;</p><p>¬∑ Une conciergerie propos√©e par We Work.</p><p><br/>
</p><p>Vous avez en vie de rejoindre un cabinet ind√©pendant o√π l‚Äôesprit entrepreneurial, l‚Äôexcellence et la bienveillance nous guident ? Alors √©crivez-nous !</p>
<!-- --> </span>
</div>"
10,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<p>Nous sommes √† la recherche d‚Äôun Big Data Engineer Snowflake S√©nior qui sera en charge des mod√©lisations data et de l‚Äôint√©gration des donn√©es: acquisition, pr√©paration, mod√©lisation et stockage, exposition, . Vous devrez faire preuve d‚Äôun √©tat d‚Äôesprit √† la fois innovant, m√©thodique, orient√© solution (et non probl√®me!), et communiquant.<br/>
<br/>
</p><p><strong>Responsabilit√©s<br/>
<br/>
</strong></p><ul><li>Analyse des besoins techniques m√©tiers, participation √† la d√©finition des architectures solution SQL, d√©veloppement et optimisation, code review, maintenir les pratiques Devops ‚ÄúYou build IT, You run IT‚Äù, support √† recette et mise en production, documentation,‚Ä¶</li><li>Mod√©lisation de la Cloud Database Snowflake</li><li>Benchmark de solutions et conseil aupr√®s de notre client sur les solutions technologiques √† adopter, en lien avec leurs besoins</li><li>Partage de connaissances et formations interne<br/>
<br/>
</li></ul><strong>Qualifications<br/>
<br/>
</strong><ul><li>Issu d‚Äôune formation sup√©rieure (√©cole d‚Äôing√©nieur, master‚Ä¶) avec une exp√©rience dans le domaine du conseil (orient√© satisfaction client et vision partenariale)</li><li>Vous disposez d‚Äôau moins 6 ann√©es d‚Äôexp√©rience dans le domaine du SQL/ETL et ayant une exp√©rience d‚Äôau moins 1 an sur Snowflake</li><li>Ma√Ætrise du d√©veloppement data (SQL, Python, ‚Ä¶) et vous disposez de solides exp√©riences dans la mise en place de pipeline de donn√©es</li><li>Ma√Ætrise d‚Äôau moins une technique de mod√©lisation: Star Sch√©ma, DataVault, DataMesh,‚Ä¶</li><li>Exp√©rience sur une plateforme Cloud (id√©alement AWS)</li><li>Exp√©rience sur des flux temps r√©el</li><li>La connaissance de concepts comme les suivants serait un +: DataOps, FinOps,..</li><li>Exp√©rience de l‚ÄôAgilit√©</li><li>Autonomie, organisation, sens du partage</li><li>Bonne communication</li><li>Orientation produit et solution<br/>
<br/>
</li></ul><strong>Additional Information<br/>
<br/>
</strong><p><u>Avantages</u>:<br/>
<br/>
</p><p>¬∑ Plan de formation pour accompagner votre carri√®re (formations √©diteurs, certifications) gr√¢ce √† nos partenariats nous accordant une position de partenaire privil√©gi√©, et management de proximit√© par des experts<br/>
<br/>
</p><p>¬∑ Top 5 du Palmar√®s Great Place to Work<br/>
<br/>
</p><p>¬∑ Si√®ge parisien situ√© √† Charles-De-Gaulle Etoile<br/>
<br/>
</p><p>¬∑ Tickets restaurants<br/>
<br/>
</p><p>¬∑ Mutuelle d‚Äôentreprise prise en charge √† 100%<br/>
<br/>
</p><p>¬∑ Prime vacances<br/>
<br/>
</p><p>¬∑ Prime de participation<br/>
<br/>
</p><p>¬∑ 1% logement<br/>
<br/>
</p><p>¬∑ RTT<br/>
<br/>
</p>
<!-- --> </span>
</div>"
11,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<p><strong>Our team context:<br/>
<br/>
</strong>Dailymotion is seeking a Junior Data Engineer to join the Data tribe. Our tribe is responsible for all the Data products at Dailymotion; your work will have an impact throughout Dailymotion‚Äôs business and help make data-driven decisions on products and strategy.<br/>
<br/>
You will join a team of Data and Machine Learning engineers who have built Software that processeshundreds of terabytes of data, billions of real-time events, hundreds of tasks automated by Airflow and millions of API calls every day. Multiple machine learning projects including recommender systems, semantic annotations, spam detection, and fraud detection.<br/>
<br/>
<strong>What we will do together:<br/>
<br/>
</strong>Our stack runs almost exclusively on Google Cloud Platform. You will work in an environment made up of Data Lakes (BigQuery, etc.), data streaming platforms (Beam / Dataflow, Flink, etc.), orchestration and scheduling platforms (Airflow), container-oriented deployment, and management platforms (Docker, K8S, Jenkins), SQL. You will also participate in data modeling activities and design of data flows until their implementation and support in production.<br/>
<br/>
<br/>
<br/>
</p><strong>Qualifications<br/>
<br/>
</strong><p><strong>Why you are a perfect candidate for us:<br/>
<br/>
</strong></p><p>‚Ä¢ You have 1+ - 3years accumulated experience as a Junior Data Engineer<br/>
‚Ä¢ You are fluent in English and French<br/>
‚Ä¢ You are a team player, continually suggesting improvements and effective collaboration.<br/>
‚Ä¢ You like to implement new technologies and innovative solutions as well as the associated prototyping.<br/>
‚Ä¢ You know how to write technical specifications.<br/>
‚Ä¢ You have hands-on experience or interest in building/managingBig Data pipelines.<br/>
‚Ä¢ You will be motivated in working onbuilding batch and streaming data streams to process a largenumber of events.<br/>
‚Ä¢ You have hands-on experience with different languages e.g.: Python, Go lang, Java, monitoring of development standards to ensure delivery of reusable and good quality code.<br/>
‚Ä¢ You have hands-on experience with different types of databases and SQL knowledge.<br/>
‚Ä¢ You have experience establishing and maintaining integration tests.<br/>
‚Ä¢ Experience on how to automate your deployments (Docker, Kubernetes, CI, Datadog...)<br/>
‚Ä¢ You have an entry-level knowledge onhow to analyze, design, or improve the efficiency, scalability, and stability of data collection, storage, and retrieval processes.<br/>
<br/>
</p><p><strong>What we offer you:<br/>
<br/>
</strong>‚Ä¢ Additional opportunities as we grow and learn together.<br/>
‚Ä¢ Join our open, collaborative culture.<br/>
‚Ä¢ Exciting, dynamic projects to work on.<br/>
‚Ä¢ Flexibility to work remotely.<br/>
<br/>
<br/>
<br/>
</p><strong>Additional Information<br/>
<br/>
</strong><p>At Dailymotion, we empower candidates to take action. If this job sounds like a great opportunity for you, be confident in your skills, we are always happy to meet you! If needed, we can accommodate our recruitment process for your special abilities.<br/>
<br/>
</p><p>Location: Paris<br/>
Type of contract: Permanent<br/>
Start Date: ASAP<br/>
<br/>
</p><p><u>For the France offices üá´üá∑<br/>
<br/>
</u></p><p>üè°Hybrid Work Framework (4 types of remote work:Full office /Flex office (1/2 days remote) / Flex remote (1/2 days at the office) / Full remote + ability to work 3 months abroad)<br/>
üí∞International Group Savings Plan offered through the Vivendi Group<br/>
üçº8weeks paid Paternity leave or Co-parental leave<br/>
üï∂Ô∏èExcellent Employee Culture (Company Events / Training / Parties / All hands ‚Ä¶)<br/>
üöÄCareer development support (training / career check-in with HR / internal mobility / compensation cycle / 360 quarter feedback review ‚Ä¶)<br/>
üè•Company-paid Health Insurance andPersonal Services Vouchers (CESU)<br/>
üöÜCommuter benefit coverage - Public Transport and Bike refund<br/>
‚õ±Ô∏èPaid Time off ‚Äì RTT and Saving time plan (CET)<br/>
‚úÖMeal Vouchers<br/>
üé°Workers representatives committee(sports membership/cinemas vouchers/gift vouchers/discount)<br/>
<br/>
</p><p><br/>
<u>Feel free to explore Dailymotionculture a little further, please check out:<br/>
<br/>
</u></p><ul><li>Dailymotion.com</li><li>New-York office - BuiltIn</li><li>Offices in France - Welcome to the Jungle</li><li>Our articles</li></ul>
<!-- --> </span>
</div>"
12,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<strong><u>Company Description</u></strong><p><br/>
</p>We are music and tech fans hailing from all over the globe, working to make Deezer the most personal music streaming service.<p><br/>
</p>From data scientists to tech experts, artists &amp; labels specialists to marketers, and even in-house music editors, our team is spreading the love for music to over 180 countries. Supporting local and international artists and bringing them closer to their fans is our mission - we believe music is about diversity, multiculturalism and togetherness.<p><br/>
</p>Ready to join the team? We're all ears.<p><br/>
</p><strong><u>Job Description</u></strong><p><br/>
</p>As part of the Operational Performance team, you will work with data analysts and data scientists on a mission to improve performance and decision-making across commercial, product and content topics.<p><br/>
</p>You will be responsible for providing them with trusted data, innovative data solutions and collaborating with the central data team on high-impact, cross-functional projects aimed at scaling our data platform and operations.<p><br/>
</p><strong><u>What You Will Do</u></strong><p><br/>
</p><ul><li>Develop a deep understanding of the business and the analysts‚Äô needs</li><li>Build and adopt software tools that help data scientists, analysts and business teams work more efficiently</li><li>Collaborate closely with the central Data Engineering team to design &amp; implement the best technical solutions</li><li>Design &amp; develop reliable data pipelines and be accountable for them</li><li>Design &amp; maintain easy to use data models, ensure their quality</li><li>Maintain data models documentations &amp; definitions available to all in our Data Catalog</li><li>Produce and maintain documentation and tutorials</li><li>Ensure data trainings for Data Analysts, developers and business users</li><li>Mentor analysts and data scientists on best practices (e.g., building testing suites and CI pipelines); driving enforcement of standards, tools and methodologies</li><li>Participate in projects planning, standups and retrospectives</li><li>Participate in the ideation process with our product managers &amp; tech leaders</li><li>Communicate proactively and manage technical issues</li></ul> Qualifications<p><br/>
</p><strong><u>What We Are Looking For</u></strong><p><br/>
</p><ul><li>2 years experience as a data engineer, BI engineer, analytics engineer or any similar role</li><li>Experience in designing, building and maintaining efficient &amp; reliable data pipelines</li><li>Proficient in SQL and with BI tools such as Tableau, Looker, ‚Ä¶</li><li>DevOps : Docker, Ops, ETL/ELT</li><li>Proficient in Python, Scala Spark is a plus</li><li>Hands-on experience on cloud technologies is a plus (Ex. Google Cloud Platform)</li><li>Strong engineering skills (code design and quality, tests, reviews, logging, monitoring, continuous integration)</li><li>Passion for technology, industry research and solving business problems</li><li>Excellent presentation and communication skills: ability to interact with stakeholders with different levels of technical expertise</li><li>Understanding of data management, data quality and data governance</li><li>Ability to own and drive projects with a creative mindset</li><li>Team player attitude</li><li>Fluent in English</li><li>Hunger for learning</li><li>Affinity with the music industry </li></ul><p><br/>
</p>Additional Information<p><br/>
</p><strong>Life @ Deezer</strong><p><br/>
</p><ul><li>Flexible working policy with up to 10 days/month remote work</li><li>Home of music : deezer premium family subscription offered, opportunity to attend private artists sessions, amazing deezer parties for employees</li><li>English or French language courses open to all</li><li>Gymlib partnership + gym room and yoga/pilates classes on site</li><li>Headquarters in the heart of Paris, at home vibe and rooftop with amazing city views</li><li>Cafeteria stocked with free drinks and snacks daily and weekly casual drinks</li><li>Hackathons &amp; meetups</li></ul><p><br/>
</p><strong>If you feel like this is the right opportunity for you, press play!</strong><p><br/>
</p><i>We are an equal opportunity employer.</i>
<!-- --> </span>
</div>"
13,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
                # You Are :<br/>
<br/>
- You have at least 3 years of Data Engineering experience within a tech company<br/>
- You have built and operated data pipelines for real customers in production systems<br/>
- You know how to put machine learning models in production<br/>
- You have a master from an engineering school<br/>
- You are able to communicate clearly in English and French<br/>
<br/>
# Environment:<br/>
<br/>
- Python, Docker, GCP, Kubernetes, Spark, Elasticsearch
<!-- --> </span>
</div>"
14,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<strong>DATA ENGINEER GCP<br/>
<br/>
</strong>Paris - FRANCE<br/>
<br/>
Open Full Remote<br/>
<br/>
55K - 75K<br/>
<br/>
Cette belle start-up dans le monde du risque recherche un Data Engineer pour une cr√©ation de poste afin d'√©pauler l'√©quipe en place.<br/>
<br/>
Son objectif ? Aider ses clients en leur facilitant l'acc√®s √† des donn√©es li√©es √† leurs domaines d'activit√©s afin d'anticiper des risques potentiels ;<br/>
<br/>
Pour le poste, on parle de Big data, Cloud et d'impl√©menter une culture DataOps.<br/>
<br/>
<strong><u>Vos Missions<br/>
</u></strong><ul><li>√ätre le lead technique sur les sujets li√©s √† la data engineering</li><li>Impl√©menter une culture DataOps</li><li>Int√©grer un gros volume de donn√©es</li><li>Construire et maintenir des pipelines de donn√©es</li><li>Optimisation de la plateforme</li><li>Participer √† la croissance de la start-up<br/>
</li></ul><strong><u>Profil Recherch√©<br/>
</u></strong><ul><li>Bac +4/5 en Ecole de Commerce, Ecole d'Ing√©nieur, ou un dipl√¥me √©quivalent</li><li>Vous justifiez d'au moins 2ans d'exp√©rience en data engineering</li><li>Python et SQL sont votre langage de tous les jours</li><li>Bonne connaissance sur GCP et Spark</li><li>La Big data n'a pas de secret pour vous</li><li>Vous √™tes sensible √† travailler dans un environnement start-up</li><li>Vous aimez le travail d'√©quipe</li><li>Vous serez parfait si en plus de tout cela, vous savez maitriser Big Query<br/>
</li></ul>Si vous √™tes int√©ress√©, merci de postuler √† ou directement via l'annonce.<br/>
<br/>
Mots cl√©s : Risk / Start-up / Python / GCP/ Spark
<!-- --> </span>
</div>"
15,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<p>La donn√©e est votre passion et vous avez la conviction que son exploitation guide les besoins m√©tier de demain. Pour vous, l‚Äôindustrialisation des traitements sur la donn√©e est indispensable ?<i> </i>Venez d√©finir et impl√©menter avec nous les architectures <i>Data Centric </i>de nos clients !</p><p><br/>
</p><p><strong>PROFIL</strong></p><p><br/>
</p><ul><li>F/H ;</li><li>Vous justifiez d‚Äôune exp√©rience significative (au moins 4 ans) en <strong>d√©veloppement</strong> et avez d√©j√† touch√© √† des <strong>technologies Big Data</strong> telles que Spark, Hadoop, Kafka ou autre.</li><li>Une connaissance d‚Äôun des √©cosyst√®mes cloud parmi AWS, Azure ou GCP est un plus.</li><li>Les bonnes pratiques de d√©veloppement, telles que le TDD ou le pair programming, ne vous sont pas inconnues.</li><li>Vous pensez que pour bien conseiller, il faut ma√Ætriser la r√©alisation.</li><li>Vous avez la conviction que<strong> la donn√©e a toute son importance</strong>, et pensez qu‚Äôelle est √† mettre en regard des besoins m√©tiers. Bref, vous aimez la donn√©e et √™tes pragmatique.</li><li>Vous avez le sens de l‚Äô√©coute et aimez <strong>partager</strong>. Les <strong>sujets technologiques vous passionnent</strong>, vous √™tes √† l‚Äôaise pour conseiller voire challenger les demandes de vos clients.</li><li>Vous aimez vous tenir au courant des nouvelles √©volutions technologiques, et pratiquez une <strong>veille</strong> r√©guli√®re.</li><li>Vous souhaitez vous confronter et contribuer √† une<strong> communaut√© de sp√©cialistes</strong>, qui ont √† c≈ìur l‚Äô√©volution des pratiques et l‚Äô<strong>apprentissage continu</strong>.</li></ul><p><br/>
</p><p><strong>DESCRIPTIF</strong></p><p><br/>
</p><p><strong>Votre mission sera de permettre la r√©alisation de projets agiles qui comportent des enjeux majeurs autour du traitement de donn√©es, ont du sens, r√©pondent √† un besoin m√©tier et s‚Äôinscrivent dans la dur√©e.</strong></p><p><br/>
</p><p>Les Octos se diff√©rencient par <strong>leurs expertises et leurs mani√®res de faire</strong> :</p><p><br/>
</p><ul><li>Nous n‚Äôh√©sitons pas √† <strong>challenger un client</strong> quand l‚Äôexp√©rience permet de proposer une solution plus adapt√©e.</li><li>Nous avons √† c≈ìur la <strong>transmission des comp√©tences</strong> au client pour permettre √† ce dernier de devenir autonome (le savoir n‚Äôest pas chasse gard√©e !).</li><li>Nous pr√©conisons la mise en place d‚Äôun<strong> accompagnement m√©thodologique</strong>, au-del√† du conseil.</li><li>Nous ne nous contentons pas d‚Äô√©mettre des pr√©conisations autour de la donn√©e, des pipelines de traitement et de l‚Äôindustrialisation : nous les <strong>d√©veloppons</strong> et nous les <strong>mettons en ≈ìuvre</strong>.</li></ul><p>Le tout en s‚Äôappuyant sur une communaut√© de sp√©cialistes <strong>de haute vol√©e</strong>.</p><p>Nos missions de data engineering :</p><ul><li>Audit et cadrage de projets (architecture, m√©thodologie, qualit√© de code),</li><li>R√©alisation/accompagnement de projets impliquant la mise en place d‚Äôarchitectures Data Centric,</li><li>Former et √©vang√©liser sur les diff√©rentes technologies que nous utilisons.</li></ul><p><br/>
</p><p>Mais ce que nous cherchons avant tout, ce sont des personnalit√©s qui enrichiront OCTO. Nous les reconnaissons √† leur volont√© de participer √† l‚Äô<strong>am√©lioration de la vie de l‚Äôentreprise</strong>, de construire la vision et les <strong>offres de demain</strong>, de partager leurs connaissances pour faciliter la <strong>mont√©e en comp√©tences</strong> r√©ciproque. De rejoindre, enfin, une communaut√© qui n‚Äôa pas peur d‚Äôaffirmer sa diff√©rence.</p>
<!-- --> </span>
</div>"
16,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
                Vos missions au quotidien<br/>
<br/>
Vous savez ¬´ faire parler ¬ª les donn√©es pour cr√©er de la valeur ? Vous souhaitez travailler en mode agile ? Rejoignez les Infrastructures Informatiques d‚Äôun Groupe en pleine transition num√©rique !<br/>
<br/>
Dans le cadre d‚Äôune √©quipe agile, en tant qu'alternant(e) Data Engineer, vous garantissez l‚Äôacc√®s aux donn√©es li√©es √† l‚Äôactivit√© de la banque. Vous impl√©mentez et industrialisez des traitements pour collecter, nettoyer et synth√©tiser des donn√©es afin de les rendre accessibles tout en veillant √† leur qualit√©.<br/>
<br/>
Concr√®tement, vous serez amen√©(e), sous la supervision de votre tuteur et/ou votre manager, √† :<br/>
<ul><li>Concevoir des solutions pour collecter, transformer et exploiter des gros volumes de donn√©es</li><li>Participer √† l‚Äôindustrialisation des traitements et √† leur am√©lioration continue pour qu‚Äôils soient fiables, robustes, performants et r√©silients afin de r√©pondre aux exigences des partenaires m√©tiers</li><li>Assurer la maintenance et l‚Äô√©volution des diff√©rents pipelines de traitement</li><li>Assurer une veille technologique afin d‚Äô√™tre √† la pointe des connaissances en mati√®re de data<br/>
<br/>
</li></ul>Et si c‚Äô√©tait vous ? <ul><li>Vous pr√©parez un Bac +4/5 en √©cole d'Ing√©nieur ou Universit√© avec une sp√©cialisation en Informatique ou Ing√©n√©rie.</li><li>Vous souaitez int√©grez une √©quipe dans un environnement tech : Hadoop Hortonworks, Kafka, Nifi, etc.</li><li>Vous √™tes curieux(se) avec un bon esprit d‚Äôanalyse et de synth√®se.</li><li>Passionn√©(e) de data, vous proposez des am√©liorations et partagez avec votre √©quipe.</li><li>Vous souhaitez enrichir vos comp√©tences techniques suivantes :</li><ul><li>Connaissances des outils Big data : Spark, Hive, Hadoop, NIFI, KAFKA, Elastic, Kibana.</li><li>Langage de d√©veloppement : Scala, Python, Devops, outils CI/CD, microservice, API.</li><li>Connaissances des architectures Big Data : R√©silience, architecture Kappa et lambda, couplage, event driven.</li></ul><li>You‚Äôre fluent in English! Vous √™tes notre candidat(e) id√©al(e) !<br/>
<br/>
</li></ul>Pensez √† accompagner votre CV de votre planning de formation !<br/>
<br/>
Plus qu‚Äôun poste, un tremplin<br/>
<br/>
D√®s votre arriv√©e, vous serez int√©gr√©(e) dans nos √©quipes et apprendrez chaque jour aux c√¥t√©s de nos experts qui vous accompagneront dans vos missions. Progressivement, vous gagnerez en autonomie sur vos projets pour faire de cette exp√©rience un vrai acc√©l√©rateur de carri√®re. Vous d√©couvrirez √©galement toute la diversit√© de nos m√©tiers, dans un secteur qui √©volue et innove en permanence.<br/>
<br/>
En tant qu‚Äôalternant(e), vous pourrez b√©n√©ficier de jours de t√©l√©travail selon le rythme de votre service et celui de votre alternance, de notre mutuelle, de primes*de participation et int√©ressement, d‚Äôune prise en charge de 50% de votre titre de transport et de la billetterie √† prix r√©duits de notre Comit√© d‚ÄôEntreprise (concerts, cin√©ma, sport‚Ä¶). Lors de votre pr√©sence sur site, vous acc√©derez √† une offre vari√©e de restaurants d‚Äôentreprise et de caf√©terias √† un tarif tr√®s comp√©titif.<br/>
<br/>
A la fin de vos √©tudes, diverses opportunit√©s pourront s‚Äôoffrir √† vous, en France et √† l‚Äôinternational.<br/>
<ul><li>Si vous avez 3 mois d‚Äôanciennet√© sur l‚Äôexercice de r√©f√©rence.<br/>
<br/>
</li></ul>Pourquoi nous choisir ?<br/>
<br/>
Chez Soci√©t√© G√©n√©rale, nous sommes convaincus que les personnes sont moteurs du changement, et que le monde de demain sera fait de toutes leurs initiatives, des plus petites aux plus ambitieuses.<br/>
<br/>
Que vous nous rejoigniez pour quelques mois, quelques ann√©es ou toute votre carri√®re, ensemble nous avons les moyens d‚Äôavoir un impact positif sur l‚Äôavenir.<br/>
<br/>
Cr√©er, oser, innover, entreprendre font partis de notre ADN. Si vous aussi vous souhaitez √™tre dans l‚Äôaction, √©voluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et d√©velopper ou renforcer votre expertise, nous sommes faits pour nous rencontrer !<br/>
<br/>
Vous h√©sitez encore ?<br/>
<br/>
Sachez que nos collaborateurs peuvent s‚Äôengager quelques jours par an pour des actions de solidarit√© sur leur temps de travail : parrainer des personnes en difficult√© dans leur orientation ou leur insertion professionnelle, participer √† l‚Äô√©ducation financi√®re de jeunes en apprentissage ou encore partager leurs comp√©tences avec une association. Les formats d‚Äôengagement sont multiples.
<!-- --> </span>
</div>"
17,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
                Description de la mission<br/>
<br/>
La Direction des Syst√®mes d‚ÄôInformation du groupe Lacoste cherche √† renforcer son √©quipe BI avec un Data Engineer dans l‚Äô√©quipe Back-Office BI. Le poste est ouvert dans une √©quipe de 5 personnes et reporte au BI Manager.<br/>
<br/>
R√¥le:<br/>
<br/>
Participer au sein de l‚Äô√©quipe BI √† la livraison des projets et √† la gestion des demandes de support et d‚Äô√©volution :<br/>
<br/>
Concevoir, d√©velopper et d√©ployer les nouveaux flux de donn√©es :<br/>
<ul><li> Concevoir et enrichir les mod√®les de donn√©es √† partir des sp√©cifications fonctionnelles et/ou des expressions de besoin m√©tier</li><li> Concevoir et d√©velopper des interfaces de chargement de donn√©es multi-sources</li><li> Recetter et d√©ployer les d√©veloppements r√©alis√©s</li><li> R√©diger et mettre √† jour la documentation technique correspondante</li><li> Pr√©parer et accompagner le passage en support<br/>
<br/>
</li></ul>Maintenir en condition op√©rationnelle les flux de donn√©es existants :<br/>
<ul><li> Suivre et am√©liorer les process d‚Äôalimentation mis en place</li><li> Enrichir les mod√®les de donn√©es m√©tiers</li><li> Modifier, compl√©ter les interfaces de chargement de donn√©es</li><li> Consommer des donn√©es de webservices / Api</li><li> Proposer des solutions d‚Äôoptimisation des mod√®les existants<br/>
<br/>
</li></ul>Superviser le monitoring des flux de donn√©es :<br/>
<ul><li> Communiquer sur le statut des flux de donn√©es</li><li> Suivre les diff√©rents plans d‚Äôactions de r√©solutions d‚Äôincidents</li><li> Proposer des solutions de pr√©vention des incidents<br/>
<br/>
</li></ul>Profil<br/>
<ul><li> Dipl√¥me d‚Äôing√©nieur ou √©quivalent (avec une premi√®re exp√©rience stage/alternance etc...sur un poste similaire)</li><li> Dot√© d‚Äôune v√©ritable culture du service : souci constant de l‚Äôutilisateur et de la qualit√© de la r√©ponse √† lui apporter</li><li> Bonne connaissance du cycle de d√©veloppement de projets data</li><li> Autonome</li><li> Exp√©rience de travail en √©quipe</li><li> Langue de travail : Fran√ßais / Anglais<br/>
<br/>
</li></ul>Comp√©tences Techniques :<br/>
<ul><li> ETL : Matillion, ODI 11</li><li> Base de donn√©es : Snowflake, Oracle 11g, SQL Server</li><li> SQL, PL/SQL, Transac SQL</li><li> Mod√©lisation de donn√©es (Data Vault)</li><li> Autres comp√©tences recherch√©es : Azure Data Factory<br/>
<br/>
</li></ul>Environnement Technique data Lacoste (en compl√©ment) :<br/>
<ul><li> Restitution : SAP Business Objects, QlikSense</li><li> M√©thodologie Traditionnel et Agile</li><li> ETL : Matillion ; ODI; Azure Data Factory</li><li> Base de donn√©es : Oracle 11g, SQL server / Snowflake</li><li> Mod√©lisation : Datavault / Star Shema</li><li> Data pr√©paration : Python (¬´ nice to have ¬ª)<br/>
<br/>
</li></ul>
<!-- --> </span>
</div>"
18,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<strong>About BlaBlaCar<br/>
<br/>
</strong>BlaBlaCar is the world‚Äôs leading carpooling platform, created with one dream in mind: leveraging technology to fill the millions of empty seats on the road. We offer long- and short-distance carpooling as well as a bus marketplace, with the mission to become the go-to marketplace for shared road mobility.<br/>
<br/>
Today, our community counts over 100 million travelers in 22 countries, creating a smarter, friendlier and carbon-saving transport network. Every year, our community saves 1.6 million tons of CO2e by sharing the road, equivalent to the CO2 emissions generated by Paris traffic in a year. But it doesn‚Äôt stop here ‚Äì our team of 250+ engineers is developing innovative algorithms to further unlock the potential of shared travel and multiply its impact.<br/>
<br/>
We‚Äôre looking for people to join our journey ‚Äì people who care, who are driven by impact and innovation, and who want to thrive in a fast-paced entrepreneurial environment. We offer a flexible workplace where we count on each other to take initiative. So join the ride ‚Äì we can‚Äôt wait to see where it takes you.<br/>
<br/>
The team‚Äôs mission is to make BlaBlaCar the go-to marketplace to book a long-distance shared ride.<br/>
<br/>
For this the Data Pro Supply team develop and run Data products to improve the efficiency and productivity of the Bus supply; including the Operated Bus in Western Europe and the Pro MarketPlace business unit in Eastern Europe and Brazil. We build dashboards and algorithms to optimize the bus operations, evaluate the demand and provide key actionable insights for the business teams.<br/>
<br/>
Your role is to own BlaBlaCar‚Äôs passenger data from the raw layer to the warehouse layer. You will work closely with Data Analysts, Data Scientists and Software Engineers on your team to continuously provide data products to make decisions on the product.<br/>
<br/>
As well, you will contribute to the Data Engineering Chapter, a horizontal group of Data Engineers, whose mission is to improve tools for Data Engineers, and make efficient the day-to-day of a Data Engineer by innovative technologies, processes etc.<br/>
<br/>
Over the past 3 years, the scope covered by Data Engineers tripled, which led the Data Organization to reformulate as a Data Mesh. This setup allows producing data products faster and autonomously as a team dedicated to a specific data domain.<br/>
<br/>
Your Responsibilities<br/>
<ul><li>You will be building efficient and robust data models for large volumes of data</li><li>You will be developing and optimizing the data workflows from the raw layer to the data mart in our data platform</li><li>You will be implementing solutions to improve the data quality</li><li>You will take a central part in the Data Engineering Chapter, defining policies and standards for data management</li></ul>Your Qualifications<br/>
<ul><li>Experience using SQL (any SQL engine experience is appreciated; we use Bigquery)</li><li>Understanding of the ETL concept, as writing ETLs will represent a big part of your daily work</li><li>Experience working with a programming or scripting language (any is appreciated; we use Python with Cloud Composer/Airflow)</li><li>Basic knowledge of UNIX, GIT</li><li>Bonus: Experience with a Cloud provider (we use GCP)</li><li>Fluency in English - French would be a plus<br/>
<br/>
</li></ul><i>If you don‚Äôt meet 100% of the qualifications outlined above, tell us why you‚Äôd still be a great fit for this role in your application!<br/>
<br/>
</i>What we have to offer<br/>
<ul><li>üåé An international environment: 45 nationalities across 6 countries: Brazil, France, Poland, Russia, Spain, and Ukraine</li><li>‚öñÔ∏è A flexible workplace: with our hybrid remote setup and family-friendly policies, we are masters of our own schedules and work-life balance, no questions asked</li><li>üí° A culture of sharing: 360 onboarding weeks, weekly team-all BlaBlaTalks to learn about what other teams are up to, Q&amp;A sessions with our leadership, shared company KPIs, ‚ÄòFail, Learn, Succeed‚Äô moments where we destigmatize and share moments of failure with others</li><li>üöÄ Innovation: Coding Nights to pitch ideas outside our roadmap and make dev‚Äô dreams come true, weekly Product &amp; Tech Demos and blogs to share engineering stories, access to top conferences across Europe</li><li>üå± Impact: building a product that has a real impact on society and the environment, and sharing an office culture that prioritizes low-waste and eco-friendly practices</li><li>üíú People-first: wind down from work at our weekly breakfasts and afterworks, or show off your talent at our annual BlaBlaShow</li><li>üß≠ Shared company principles that guide us in our everyday decision-making and bring us closer to our goal. Find out more about our BlaBlaPrinciples</li><li>üöóFree carpooling &amp; üöå bus-rides wherever whenever</li></ul>Interested in joining the ride? Here‚Äôs what your hiring journey will look like.<br/>
<ul><li>a 30 min video-call with Elodie, our Talent Acquisition Manager to get to know you, understand your career expectations and answer your questions</li><li>a 45-min video-call interview with Celia, your future manager</li><li>A 45-min technical interview with: 45 min with some Data Engineers, Data Analysts and Software Engineers from the team</li><li>A 30-min informal discussion with Emmanuel, our VP Data</li></ul>BlaBlaCar is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.
<!-- --> </span>
</div>"
19,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<strong>Pr√©sentation de la direction g√©n√©rale et du service<br/>
<br/>
</strong>L'Institut d'√©mission des d√©partements d'outre-mer (IEDOM) exerce ses missions au sein de l'Eurosyst√®me, compos√© de la banque centrale europ√©enne et des banques centrales nationales de la zone euro. L'IEDOM est charg√© d'assurer la continuit√© territoriale des missions de banque centrale par d√©l√©gation de la Banque de France dans les d√©partements et collectivit√©s d'outre-mer dont la monnaie est l'euro : Guadeloupe, Guyane, Martinique, Mayotte, La R√©union, Saint-Barth√©lemy, Saint-Martin, Saint-Pierre-et-Miquelon et les Terres australes et antarctiques fran√ßaises (TAAF).<br/>
<br/>
Vous √™tes passionn√©(e) par la data, saisissez l'opportunit√© de nous accompagner dans le d√©veloppement de notre socle de donn√©es et acc√©l√©rons ensemble notre transformation digitale.<br/>
<br/>
Nous recrutons un(e) Data Engineer H/F qui sera notre leader technique pour l‚Äôacquisition, la transformation et la restitution de la donn√©e aux utilisateurs et aux applications de l‚ÄôIEDOM . Rattach√©(e) √† la Division des Syst√®mes d‚ÄôInformation, vous travaillez au sein de l'√©quipe Etudes et Donn√©es - ETD. L'√©quipe ETD regroupe un ensemble d‚Äôexperts et de chefs de projets en charge de la conception, de la r√©alisation et de l‚Äôassistance √† l‚Äôexploitation des applications m√©tiers (BI, Business analyste, chefs de projets informatiques pour les m√©tiers). Votre mission est de rendre les donn√©es de l'entreprise accessibles et propres pour supporter et acc√©l√©rer la cr√©ation de valeur par les utilisateurs m√©tiers et faciliter la transformation digitale.<br/>
<br/>
<strong>Descriptif de mission<br/>
</strong><ul><li> Vous concevez les flux de collecte, d'ingestion et de transformation des donn√©es pour alimenter notre socle de donn√©es internalis√©, bas√© sur les technologies Talend ‚Äì BO ‚Äì JEDOX et participez √† leur d√©veloppement ainsi qu‚Äô√† leur maintenance.</li><li> Vous mettez les donn√©es √† la disposition des utilisateurs, dans le respect des normes et r√®gles en vigueur (RGPD, s√©curit√©, gouvernance interne...)</li><li> Vous faites de la veille technologique afin d'√™tre force de proposition.</li><li> Vous √™tes responsable : Des livraisons / De l'architecture data (flux, contr√¥les, s√©curit√©, historisation, suppression etc.) / De la strat√©gie d'impl√©mentation sur le socle internalis√© / De la strat√©gie d'impl√©mentation des flux de donn√©es avec Talend.</li><li> Vous assurez le support de niveau 2 aux incidents de production</li><li> Vous assurez le r√¥le de Lead d√©veloppeur sur la plateforme DATA.<br/>
<br/>
</li></ul><strong>Profil recherch√©<br/>
<br/>
</strong>Vous √™tes organis√©(e), rigoureux(se) et appr√©ciez le travail en √©quipe. Vous √™tes naturellement curieux(se) et vous int√©ressez aux m√©tiers et activit√©s pour lesquels vous travaillez.<br/>
<br/>
De formation Bac +5 avec 5 ans d'exp√©riences, vous maitrisez un ou plusieurs outils de type ETL/ELT (de pr√©f√©rence Talend).<br/>
<br/>
Vous avez une exp√©rience significative et r√©ussie sur l'impl√©mentation d'un socle de donn√©es (Datawarehouse, Datalake, ...) dans un contexte On-premise.<br/>
<br/>
Vous avez une exp√©rience sur les environnements BO.<br/>
<br/>
Vous √™tes familier avec le concept DevOps et les m√©thodes agiles.<br/>
<br/>
Vous avez des connaissances en mod√©lisation de donn√©es, MDM.<br/>
<br/>
Contactez nos ambassadeurs<br/>
<br/>
La Banque de France est une institution socialement responsable, attach√©e au respect de la diversit√© sous toutes ses formes, √† la lutte contre les discriminations, √† favoriser la parit√© Femme/Homme et √† garantir un environnement de travail de qualit√©. Des am√©nagements de poste peuvent √™tre organis√©s pour tenir compte des handicaps des personnes recrut√©es.
<!-- --> </span>
</div>"
20,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<strong>NOTRE AMBITION : Garantir la qualit√© de nos produits<br/>
<br/>
</strong>Permettre aux √©quipes, et √† nos clients, d‚Äôacc√©der √† des donn√©es fiables et de couvrir leurs besoins dans chaque domaine ! Nous d√©veloppons :<br/>
<ul><li>Des reports √† destination de nos clients.</li><li>Des calculs d‚Äôindicateurs strat√©giques.</li><li>Des dashboards de pilotage, de launch control et de discovery.</li><li>Des reporting et des analyses de donn√©es.</li><li>Des contr√¥les industrialis√©s et des alertes.</li><li>Des flux de donn√©es avec nos partenaires.<br/>
<br/>
</li></ul><strong>NOTRE M√âTHODE DE TRAVAIL :<br/>
<br/>
</strong>Nous sommes 10 dans l‚Äô√©quipe Data (Head of Data, Team Lead BI, Data Analysts &amp; Data Engineers) r√©partis entre 2 squads. Rattach√©s au p√¥le Product &amp; Tech, nous collaborons avec toutes les √©quipes de PayPlug.<br/>
<br/>
Pour relever les challenges m√©tiers et clients, nous construisons une plateforme de donn√©es sur GCP (Google Cloud Platform), sur laquelle nous d√©veloppons nos pipelines et nos solutions. Celle-ci remplacera √† terme int√©gralement notre syst√®me existant. Les d√©veloppements se font principalement en SQL et Python.<br/>
<br/>
Notre stack technique :<br/>
<ul><li>Data : BigQuery, Cloud Composer/Apache Airlfow, Cloud Data Proc, Cloud PubSub</li><li>BI: Tableau</li><li>Infrastructure g√©n√©rale : Google Cloud Platform</li><li>Conteneur et Orchestration : Docker, Kubernetes</li><li>Versionning et CI/CD : gitlab &amp; gitlab-CI</li><li>Databases : BigQuery, MongoDB, MySQL, Vertica</li><li>Message broker : RabbitMQ<br/>
<br/>
</li></ul>Tes missions<br/>
<br/>
Tu int√©greras la squad Data, compos√©e d‚Äôun data engineer, d‚Äôun Lead Technique et rattach√©e au Head of Data. Le r√¥le de cette squad est cl√© dans la construction et le maintien de la plateforme de donn√©es !<br/>
<br/>
Tu assureras la mise en place des flux et mod√®les de donn√©es, en fonction des usages m√©tiers.<br/>
<br/>
Tu seras garant de la qualit√© des donn√©es, du maintien des pipelines, de la documentation et de la performance de nos solutions.<br/>
<br/>
Dans tes missions tu seras aussi amen√© √† √©changer avec les autres √©quipes de Product &amp; Tech (SRE, squads Product &amp; Tech, squad BI, ‚Ä¶).<br/>
<br/>
<strong>Requirements<br/>
</strong><ul><li>Data engineer avec au moins une premi√®re exp√©rience. </li><li>Tu as d√©j√† d√©velopp√© en SQL et python. </li><li>Tu as d√©j√† travaill√© sur une ou plusieurs plateformes cloud, de pr√©f√©rence GCP.</li><li>Tu as de l‚Äôexp√©rience dans la construction, le maintien de pipelines de donn√©es, la mod√©lisation, le monitoring et l‚Äôalerting.</li><li>Autonome et rigoureux.se, tu as de bonnes qualit√©s relationnelles, ainsi qu‚Äôun bon esprit d‚Äô√©quipe.<br/>
<br/>
</li></ul><strong>Ce qui te d√©marque :<br/>
</strong><ul><li>De nature curieuse, tu aimes investiguer et comprendre les usages et pratiques en data engineering. </li><li>Tu as de l‚Äôexp√©rience avec le production-grade code (design pattern, test unitaire et d‚Äôint√©gration, CI/CD, ‚Ä¶)</li><li>Tu souhaites rejoindre une nouvelle √©quipe et construire une plateforme de donn√©es modernes et scalables. </li><li>√Ä l‚Äô√©coute, tu es soucieux.se de r√©pondre aux besoins de tes coll√®gues. <br/>
<br/>
</li></ul>Hiring Process<br/>
<ul><li>Appel de qualification avec Justine, Talent Managers (20-30') ;</li><li>Interview avec Mathilde, Head of Data</li><li>Test avec l‚Äô√©quipe Data (1h30) ;</li><li>Interview avec Christophe, VP Engineering (30‚Äô) </li><li>2 r√©f√©rences.<br/>
<br/>
</li></ul><strong>Benefits<br/>
<br/>
</strong><strong>Modalit√©s / avantages de travai</strong>l :<br/>
<ul><li>Organisation de travail hybride ;</li><li>25 CP / an &amp; 10 RTT / an ;</li><li>Des bureaux dans le 13e arrondissement de Paris (Biblioth√®que Fran√ßois Mitterrand).<br/>
<br/>
</li></ul><strong>Avantages financiers</strong> :<br/>
<ul><li>Carte Apetiz (titres restaurants) d‚Äôune valeur de 9‚Ç¨ par jour (52% pris en charge) ;</li><li>Sant√© / Famille : Mutuelle sant√© Malakoff Humanis </li><li>Abonnements aux transports publics ou Velib pris en charge √† 50% par PayPlug.<br/>
<br/>
</li></ul><strong>Autres</strong> :<br/>
<ul><li>Moka.care pour le soutien √† la sant√© mentale de chacun ;</li><li>Windoo : activit√©s de sport, bien-√™tre et d√©veloppement personnel en ligne ;</li></ul>
<!-- --> </span>
</div>"
21,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<strong><u>Description</u></strong><p><br/>
</p><i><strong>About Us:</strong></i><p><br/>
</p>Since 2015, Cognism has been a trusted leader in international sales intelligence, setting a new standard for data quality and compliance, trusted by 1000+ revenue teams worldwide.<p><br/>
</p>Cognism has helped thousands of sales teams to find, engage and close their dream prospects by providing them with a blend of real-time company, people and event data.<p><br/>
</p>One of our main goals, is to hire individuals who want to grow, develop and build on their already thriving careers and we work hard to help you achieve any goals you have, while having fun along the way.<p><br/>
</p>There hasn‚Äôt been a more exciting time to join us, we have just been through our Series C funding to enhance our global presence and we have just been named as one of the Top 15 startups in the UK by LinkedIn, for the 3rd year running!<p><br/>
</p>For more information on Cognism‚Äôs intuitive sales intelligence platform powered by world-leading data, compliance and targeting, please visit www.cognism.com.<p><br/>
</p><strong><u>Summary</u></strong><p><br/>
</p>We are now looking for an experienced Data Engineer to join our fast-growing team. You will be responsible for expanding and optimizing our data asset and data pipeline, as well as building new systems that collect, manage, and convert raw data into usable information for data scientists and business analysts to interpret.<p><br/>
</p>The ideal candidate is an experienced with big data pipelines and a natural data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.<p><br/>
</p>If you are detail-oriented, with excellent organizational skills and experience in this field, we‚Äôd like to hear from you.<p><br/>
</p><strong><u>Requirements</u></strong><p><br/>
</p><ul><li>Have a 5+ years of experience as a software engineer</li><li>Have a degree in Computer Science, Computer Engineering, Applied Statistics, Mathematics, or a related field (or you are in the process of achieving one).</li><li>Have some programming experience with Scala/Java/Python and SQL and are familiar with the principles of software engineering and data analytics.</li><li>Be excited to try new technologies and develop your technical skills.</li><li>Have know-how of designing and interacting with databases (SQL/NoSql).</li><li>Have experience with AWS-based database systems.</li><li>Be familiar with GIT and release engineering strategies.</li><li>Be proficient in spoken and written English.</li></ul><p><br/>
</p><strong><u>Responsibilities</u></strong><p><br/>
</p><ul><li>Optimizing and improving existing data pipelines</li><li>Building new systems that collect, manage, and convert raw data into usable information.</li><li>Support software developers, database architects, data analysts and data scientists on data initiatives</li><li>Participate in all phases of software development including concept, design, prototyping, and production release</li><li>Work directly with non-technical associates to understand business requirements</li></ul><p><br/>
</p><strong><u>Benefits</u></strong><p><br/>
</p><ul><li>Competitive salary based on the level of experience</li><li>24 days‚Äô holiday PLUS all the usual public holidays</li><li>Flexible working hours, with the ability to work from home</li><li>Work with the latest technology paradigms</li><li>Access to education opportunities (books, courses, seminars, conferences)</li><li>Access to Cognism‚Äôs Employee Assistance Programme with Health Assured</li><li>Monthly Wellbeing Allowance</li><li>Remote Workouts and Social activities</li></ul>
<!-- --> </span>
</div>"
22,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
<p><strong>DATA ENGINEER ‚Äì PLATEFORME SaaS - CDI</strong></p><p><strong>PARIS (75)</strong></p><p><strong>70K‚Äì80K EUR</strong></p><p><br/>
</p><p><strong> Stack : Python / SQL / BigQuery / Metabase / Jenkins / GCP</strong></p><p><br/>
</p><p><i>Dans le cadre d'une cr√©ation de poste, rejoignez l'√©quipe Data Engineering d'une start-up sp√©cialis√©e dans la cr√©ation de contenu sur-mesure. </i></p><p><br/>
</p><p><strong>LE R√îLE</strong></p><p>Rattach√©.e au VP Engineering et en bin√¥me avec le Data Engineer actuel, vous interviendrez notamment sur les missions suivantes : </p><ul><li>Recueillir et challenger les besoins des √©quipes m√©tiers,</li><li>Participer √† l'enrichissement et l'am√©lioration de la plateforme Data en lien avec le Data Engineer actuel, </li><li>D√©velopper des dashboardings et reportings √† destination du business, </li><li>Veiller √† la s√©curit√©, scalabilit√© et flexibilit√© de la plateforme Data. </li></ul><p><br/>
</p><p><strong>VOTRE PROFIL</strong></p><ul><li>Vous justifiez de 4+ ann√©es d'exp√©rience sur un poste similaire,</li><li>Vous √™tes un.e expert.e SQL / Python,</li><li>Vous avez id√©alement une premi√®re exp√©rience dans un environnement GCP,</li><li>Vous disposez d'un excellent relationnel et avez une app√©tence pour l'aspect technico-fonctionnel.</li><li>Vous parlez couramment anglais.</li></ul><p><br/>
</p><p><strong>TELETRAVAIL</strong></p><ul><li>Full Remote possible, avec possibilit√© de t√©l√©travailler depuis l'√©tranger</li></ul><p><br/>
</p><p><strong>PROCESSUS DE RECRUTEMENT</strong></p><ul><li>Echange avec le Talent Acquisition Manager</li><li>Echange technique avec le VP Engineering et le Data Engineer actuel</li><li>Dernier √©change avec le CTO</li></ul><p><br/>
</p><p><strong>COMMENT POSTULER ?</strong></p><p>Si vous √™tes int√©ress√©.e, merci de faire part de votre CV √† Benjamin Remy.</p>
<!-- --> </span>
</div>"
23,"<div class=""jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch"" id=""job-details"" tabindex=""-1"">
<h2 class=""mt5 t-20 t-bold mb4"">
            √Ä propos de l‚Äôoffre d‚Äôemploi
          </h2>
<!-- -->
<!-- --> <span>
                Vos missions au quotidien<br/>
<br/>
Au sein de la Direction des Syst√®mes d‚ÄôInformation de la banque de d√©tail France de la Soci√©t√© G√©n√©rale vous ‚Ä¶<br/>
<br/>
<strong>B√©n√©ficierez d‚Äôun cadre de travail agr√©able </strong>facilitant l‚Äô√©quilibre vie pro/vie perso notamment en permettant jusqu‚Äô√† 3 jours de t√©l√©travail par semaine.<br/>
<br/>
<strong>Evoluerez dans un environnement stimulant </strong>: cr√©er, oser et innover, font partie de notre ADN. Alors si vous aimez √™tre dans l‚Äôaction, travailler sur les projets innovants et vous sentir utile au quotidien, n‚Äôh√©sitez plus ! Int√©grez nos √©quipes afin de relever les d√©fis qui nous animent au quotidien autour des <strong>pratiques de d√©veloppement green, du cloud, de la data ou encore de la cybers√©curit√©.<br/>
<br/>
</strong><strong>Baignerez dans une culture bienveillante : </strong>notre proximit√© avec le m√©tier, l‚Äôentraide et l‚Äô√©coute entre management et la communaut√© des experts font notre force. Un collectif pl√©biscit√© par 85% de nos collaborateurs*.<br/>
<br/>
<strong>En tant que data engineer, </strong>vous serez rattach√©(e) √† une Feature Team agile d√©di√©e √† la banque de financement et d'investissement au service des entreprises, des investisseurs et du public en France et dans le reste du monde.<br/>
<br/>
D√©tection de fraude en temps r√©el, anonymisation de donn√©es ou encore am√©lioration de moteurs de recommandation, vous cr√©ez des architectures qui r√©pondent aux probl√©matiques de masse de donn√©es, de rapidit√© et de volume. Bref, un(e) vrai(e) maestro de la data‚ÄØ!<br/>
<br/>
Concr√™tement, vous serez amen√©(e) √†:<br/>
<ul><li>Concevoir des solutions pour collecter, nettoyer, organiser et synth√©tiser de gros volumes de donn√©es (pour alimenter bases de donn√©es, datalakes et projets Big Data) </li><li>Travailler en √©troite collaboration avec les Data Architectes et Data Scientists pour industrialiser le proc√©d√© et produire des analyses op√©rationnelles </li><li>Participer √† l‚Äôanalyse complexe de donn√©es provenant de diff√©rentes sources </li><li>Assurer une veille technologique permettant de tester de nouvelles fonctionnalit√©s et nouveaux outils <br/>
<br/>
</li></ul>Et si c‚Äô√©tait vous ?<br/>
<br/>
Vous √™tes curieux(se), avec un bon esprit d‚Äôanalyse et de synth√®se<br/>
<br/>
Passionn√©(e) de data, vous proposez des am√©liorations et partagez avec votre √©quipe<br/>
<br/>
You‚Äôre fluent in English!<br/>
<br/>
Incollable sur Spark et Scala, vous aimez √©galement d√©velopper en Python<br/>
<br/>
Vous √™tes dipl√¥m√©(e) d‚Äôun Bac +5 en informatique / √©cole d‚Äôing√©nieur et avez une premi√®re exp√©rience dans un environnement tech‚ÄØ: Hadoop Hortonworks, Kafka, Nifi, etc.<br/>
<br/>
Plus qu‚Äôun poste, un tremplin<br/>
<br/>
<strong>A la Soci√©t√© G√©n√©rale</strong>, nous sommes convaincus que les personnes sont moteurs du changement et que le monde de demain sera fait de toutes leurs initiatives, des plus petites aux plus ambitieuses.<br/>
<br/>
Aux 4 coins du monde, que vous nous rejoigniez pour quelques mois, quelques ann√©es ou toute votre carri√®re, ensemble nous avons les moyens d‚Äôavoir un impact positif sur l‚Äôavenir. Cr√©er, oser, innover, entreprendre font partie de notre ADN.<br/>
<br/>
Si vous aussi vous souhaitez √™tre dans l‚Äôaction, √©voluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et d√©velopper ou renforcer votre expertise, nous sommes faits pour nous rencontrer !<br/>
<br/>
Vous h√©sitez encore ?<br/>
<br/>
Sachez que nos collaborateurs peuvent s‚Äôengager quelques jours par an pour des actions de solidarit√© sur leur temps de travail : parrainer des personnes en difficult√© dans leur orientation ou leur insertion professionnelle, participer √† l‚Äô√©ducation financi√®re de jeunes en apprentissage ou encore partager leurs comp√©tences avec une association. Les formats d‚Äôengagement sont multiples.<br/>
<br/>
Pourquoi nous choisir ?<br/>
<br/>
Rejoindre notre communaut√© Data, c‚Äôest se donner la chance d‚Äôavoir une vraie carri√®re d‚Äôexpertise : monter en comp√©tences gr√¢ce √† nos parcours de formation ou encore participer √† des √©v√©nements tech et pouvoir √©changer avec ses pairs issus des 4 coins du monde. Vous pourrez √©voluer vers les m√©tiers de Data Scientist, Architecte technique ou Expert D√©veloppement SI.
<!-- --> </span>
</div>"
24,"Good grasp of big data infrastructures and relevant big data tools.
Fusion of extremely structured, semi-structured and unstructured data sources (e.g.‚Ä¶"
25,"Uphold data security and data governance best practises.
You will have hands-on data processing and data modeling experience in a ‚Äúbig data‚Äù environment, with‚Ä¶"
26,The Data Access team is a new team at Indeed which is responsible for building systems that administer and enforce Indeed‚Äôs access policies over hundreds of‚Ä¶
27,"Design and plan enterprise-scale cloud environments including application dependencies, data storage and flow, network connectivity and overall cloud hosting."
28,We provide paid training in technical and soft skills to take your skills to the next level in exchange for a 12 month commitment to work with an established‚Ä¶
29,"The successful candidate will have hands-on data processing and data modeling experience in a ‚Äúbig data‚Äù environment.
Seattle 132,000 - 192,000 USD per year."
30,"Load and performance test data pipelines built using the above-mentioned technologies.
Knowledge or experience in architectural best practices in building data‚Ä¶"
31,"Proficient with data warehouse architecture and data pipelines (ELT/ETL, data modeling).
6 years‚Äô experience with data & analytics toolsets, including data‚Ä¶"
32,"Interfacing with other engineers to extract, transform, and load (ETL) data from a wide variety of in-house and third-party data sources."
